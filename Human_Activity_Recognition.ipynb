{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing all the necessary packages and libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the 6 classes\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Function for Confusion Matrix\n",
    "def confusion_matrix2(Y_true, Y_pred, ACTIVITIES):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = 'UCI_HAR_Dataset'\n",
    "\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Function to load the signals data\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).to_numpy()\n",
    "        ) \n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return y.values\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time steps :  128\n",
      "Input dimensions :  9\n",
      "Len of X_train :  7352\n"
     ]
    }
   ],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))\n",
    "\n",
    "# Loading the Train and Test Data\n",
    "X_train, X_test, Y_train, Y_test = load_data()\n",
    "\n",
    "y_train_dif, y_test_dif = pd.Series(Y_train).map(dict(zip(range(1,7), [1]*3+[0]*3))).values, pd.Series(Y_test).map(dict(zip(range(1,7), [1]*3+[0]*3))).values\n",
    "\n",
    "# Dynamic class data\n",
    "X_train_Dynamic, X_test_Dynamic = X_train[y_train_dif==1], X_test[y_test_dif==1]\n",
    "Y_train_Dynamic, Y_test_Dynamic = Y_train[y_train_dif==1], Y_test[y_test_dif==1] \n",
    "\n",
    "# Static class data\n",
    "X_train_Static, X_test_Static = X_train[y_train_dif==0], X_test[y_test_dif==0]\n",
    "Y_train_Static, Y_test_Static = Y_train[y_train_dif==0], Y_test[y_test_dif==0]\n",
    "\n",
    "y_train_dif, y_test_dif = pd.get_dummies(y_train_dif).values,pd.get_dummies(y_test_dif).values\n",
    "Y_train_Dynamic, Y_test_Dynamic = pd.get_dummies(Y_train_Dynamic).values, pd.get_dummies(Y_test_Dynamic).values\n",
    "Y_train_Static, Y_test_Static = pd.get_dummies(Y_train_Static).values, pd.get_dummies(Y_test_Static).values\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "\n",
    "print(\"Time steps : \", timesteps)\n",
    "print(\"Input dimensions : \", input_dim)\n",
    "print(\"Len of X_train : \", len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide and Conquer CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:Large dropout rate: 0.65 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 126, 16)           448       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 63, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1008)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1008)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                16144     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 16,690\n",
      "Trainable params: 16,658\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(16, 3, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001), input_shape=(timesteps, input_dim)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.65))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Karan Kapadia\\Anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.3187 - accuracy: 0.8904 - val_loss: 0.0747 - val_accuracy: 0.9844\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 6s 834us/step - loss: 0.1425 - accuracy: 0.9652 - val_loss: 0.0580 - val_accuracy: 0.9939\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 6s 850us/step - loss: 0.1350 - accuracy: 0.9693 - val_loss: 0.0535 - val_accuracy: 0.9949\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 6s 843us/step - loss: 0.1417 - accuracy: 0.9706 - val_loss: 0.0566 - val_accuracy: 0.9942\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 6s 780us/step - loss: 0.1061 - accuracy: 0.9818 - val_loss: 0.0527 - val_accuracy: 0.9922\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 6s 780us/step - loss: 0.0961 - accuracy: 0.9835 - val_loss: 0.0506 - val_accuracy: 0.9922\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 6s 781us/step - loss: 0.0892 - accuracy: 0.9837 - val_loss: 0.0446 - val_accuracy: 0.9963\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 6s 840us/step - loss: 0.0971 - accuracy: 0.9819 - val_loss: 0.0545 - val_accuracy: 0.9881\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 6s 852us/step - loss: 0.0866 - accuracy: 0.9856 - val_loss: 0.0383 - val_accuracy: 0.9983\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 6s 842us/step - loss: 0.0993 - accuracy: 0.9801 - val_loss: 0.0490 - val_accuracy: 0.9898\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 6s 876us/step - loss: 0.0837 - accuracy: 0.9879 - val_loss: 0.0393 - val_accuracy: 0.9963\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 6s 795us/step - loss: 0.0788 - accuracy: 0.9874 - val_loss: 0.0336 - val_accuracy: 0.9990\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 6s 777us/step - loss: 0.1005 - accuracy: 0.9808 - val_loss: 0.0399 - val_accuracy: 0.9969\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 6s 789us/step - loss: 0.0772 - accuracy: 0.9883 - val_loss: 0.0357 - val_accuracy: 0.9983\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 6s 810us/step - loss: 0.0737 - accuracy: 0.9874 - val_loss: 0.0290 - val_accuracy: 0.9993\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 6s 831us/step - loss: 0.0677 - accuracy: 0.9897 - val_loss: 0.0288 - val_accuracy: 0.9980\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 6s 778us/step - loss: 0.0681 - accuracy: 0.9882 - val_loss: 0.0237 - val_accuracy: 0.9997\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 6s 779us/step - loss: 0.0649 - accuracy: 0.9890 - val_loss: 0.0238 - val_accuracy: 0.9993\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 6s 772us/step - loss: 0.0478 - accuracy: 0.9913 - val_loss: 0.0204 - val_accuracy: 0.9997\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 6s 779us/step - loss: 0.0447 - accuracy: 0.9922 - val_loss: 0.0158 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18f9bfd84c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          y_train_dif,\n",
    "          batch_size=8,\n",
    "          validation_data=(X_test, y_test_dif),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     Dynamic  Static\n",
      "True                    \n",
      "Dynamic     1387       0\n",
      "Static         0    1560\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix2(y_test_dif, model.predict(X_test), {0: 'Static', 1: 'Dynamic',}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 0s 74us/step\n",
      "[0.01575663369774697, 1.0]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_dif)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('class_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"red\"> Observations </font></h1> \n",
    "\n",
    "- 2- class classifer has 100 % validation accuracy.\n",
    "- Which means that our model can perfectly distinguish static and dynamic activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Dynamic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 126, 64)           1792      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 124, 32)           6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                63520     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 71,715\n",
      "Trainable params: 71,651\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 3, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001), input_shape=(timesteps, input_dim)))\n",
    "model.add(Conv1D(32, 3, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.001), input_shape=(timesteps, input_dim)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3285 samples, validate on 1387 samples\n",
      "Epoch 1/49\n",
      "3285/3285 [==============================] - 3s 1ms/step - loss: 1.5175 - accuracy: 0.4514 - val_loss: 1.0317 - val_accuracy: 0.6410\n",
      "Epoch 2/49\n",
      "3285/3285 [==============================] - 3s 894us/step - loss: 0.7712 - accuracy: 0.7486 - val_loss: 0.6647 - val_accuracy: 0.8169\n",
      "Epoch 3/49\n",
      "3285/3285 [==============================] - 3s 908us/step - loss: 0.5382 - accuracy: 0.8633 - val_loss: 0.6644 - val_accuracy: 0.7830\n",
      "Epoch 4/49\n",
      "3285/3285 [==============================] - 3s 891us/step - loss: 0.4462 - accuracy: 0.8992 - val_loss: 0.4809 - val_accuracy: 0.8782\n",
      "Epoch 5/49\n",
      "3285/3285 [==============================] - 3s 867us/step - loss: 0.3918 - accuracy: 0.9199 - val_loss: 0.3956 - val_accuracy: 0.9005\n",
      "Epoch 6/49\n",
      "3285/3285 [==============================] - 3s 850us/step - loss: 0.3862 - accuracy: 0.9285 - val_loss: 0.5752 - val_accuracy: 0.8659\n",
      "Epoch 7/49\n",
      "3285/3285 [==============================] - 3s 849us/step - loss: 0.3321 - accuracy: 0.9467 - val_loss: 0.3282 - val_accuracy: 0.9402\n",
      "Epoch 8/49\n",
      "3285/3285 [==============================] - 3s 869us/step - loss: 0.3094 - accuracy: 0.9540 - val_loss: 0.3538 - val_accuracy: 0.9358\n",
      "Epoch 9/49\n",
      "3285/3285 [==============================] - 3s 841us/step - loss: 0.2876 - accuracy: 0.9592 - val_loss: 0.3773 - val_accuracy: 0.9250\n",
      "Epoch 10/49\n",
      "3285/3285 [==============================] - 3s 887us/step - loss: 0.3026 - accuracy: 0.9565 - val_loss: 0.3909 - val_accuracy: 0.9466\n",
      "Epoch 11/49\n",
      "3285/3285 [==============================] - 3s 910us/step - loss: 0.3115 - accuracy: 0.9507 - val_loss: 0.5067 - val_accuracy: 0.8767\n",
      "Epoch 12/49\n",
      "3285/3285 [==============================] - 3s 903us/step - loss: 0.2994 - accuracy: 0.9556 - val_loss: 0.2647 - val_accuracy: 0.9567\n",
      "Epoch 13/49\n",
      "3285/3285 [==============================] - 3s 863us/step - loss: 0.3018 - accuracy: 0.9534 - val_loss: 0.2676 - val_accuracy: 0.9575\n",
      "Epoch 14/49\n",
      "3285/3285 [==============================] - 3s 845us/step - loss: 0.2704 - accuracy: 0.9616 - val_loss: 1.2183 - val_accuracy: 0.6979\n",
      "Epoch 15/49\n",
      "3285/3285 [==============================] - 3s 870us/step - loss: 0.2856 - accuracy: 0.9613 - val_loss: 0.3476 - val_accuracy: 0.9430\n",
      "Epoch 16/49\n",
      "3285/3285 [==============================] - 3s 887us/step - loss: 0.2892 - accuracy: 0.9571 - val_loss: 0.3635 - val_accuracy: 0.9308\n",
      "Epoch 17/49\n",
      "3285/3285 [==============================] - 3s 830us/step - loss: 0.2732 - accuracy: 0.9623 - val_loss: 0.2850 - val_accuracy: 0.9553\n",
      "Epoch 18/49\n",
      "3285/3285 [==============================] - 3s 857us/step - loss: 0.2661 - accuracy: 0.9619 - val_loss: 0.3080 - val_accuracy: 0.9531\n",
      "Epoch 19/49\n",
      "3285/3285 [==============================] - 3s 905us/step - loss: 0.2626 - accuracy: 0.9623 - val_loss: 0.2695 - val_accuracy: 0.9654\n",
      "Epoch 20/49\n",
      "3285/3285 [==============================] - 3s 895us/step - loss: 0.2981 - accuracy: 0.9546 - val_loss: 0.2530 - val_accuracy: 0.9676\n",
      "Epoch 21/49\n",
      "3285/3285 [==============================] - 3s 847us/step - loss: 0.2415 - accuracy: 0.9723 - val_loss: 0.4838 - val_accuracy: 0.9041\n",
      "Epoch 22/49\n",
      "3285/3285 [==============================] - 3s 837us/step - loss: 0.2403 - accuracy: 0.9686 - val_loss: 0.3731 - val_accuracy: 0.9438\n",
      "Epoch 23/49\n",
      "3285/3285 [==============================] - 3s 842us/step - loss: 0.2152 - accuracy: 0.9763 - val_loss: 0.6386 - val_accuracy: 0.8508\n",
      "Epoch 24/49\n",
      "3285/3285 [==============================] - 3s 835us/step - loss: 0.4051 - accuracy: 0.9151 - val_loss: 0.2754 - val_accuracy: 0.9719\n",
      "Epoch 25/49\n",
      "3285/3285 [==============================] - 3s 835us/step - loss: 0.3170 - accuracy: 0.9364 - val_loss: 0.2864 - val_accuracy: 0.9603\n",
      "Epoch 26/49\n",
      "3285/3285 [==============================] - 3s 835us/step - loss: 0.3125 - accuracy: 0.9452 - val_loss: 0.2343 - val_accuracy: 0.9676\n",
      "Epoch 27/49\n",
      "3285/3285 [==============================] - 3s 850us/step - loss: 0.2933 - accuracy: 0.9470 - val_loss: 0.5349 - val_accuracy: 0.8774\n",
      "Epoch 28/49\n",
      "3285/3285 [==============================] - 3s 833us/step - loss: 0.2960 - accuracy: 0.9522 - val_loss: 0.2474 - val_accuracy: 0.9697\n",
      "Epoch 29/49\n",
      "3285/3285 [==============================] - 3s 835us/step - loss: 0.2408 - accuracy: 0.9732 - val_loss: 0.2108 - val_accuracy: 0.9726\n",
      "Epoch 30/49\n",
      "3285/3285 [==============================] - 3s 837us/step - loss: 0.2347 - accuracy: 0.9693 - val_loss: 0.4800 - val_accuracy: 0.9257\n",
      "Epoch 31/49\n",
      "3285/3285 [==============================] - 3s 830us/step - loss: 0.2160 - accuracy: 0.9775 - val_loss: 0.3916 - val_accuracy: 0.9452\n",
      "Epoch 32/49\n",
      "3285/3285 [==============================] - 3s 838us/step - loss: 0.2481 - accuracy: 0.9665 - val_loss: 0.4799 - val_accuracy: 0.9178\n",
      "Epoch 33/49\n",
      "3285/3285 [==============================] - 3s 834us/step - loss: 0.2298 - accuracy: 0.9671 - val_loss: 0.5751 - val_accuracy: 0.9229\n",
      "Epoch 34/49\n",
      "3285/3285 [==============================] - 3s 840us/step - loss: 0.2154 - accuracy: 0.9717 - val_loss: 0.4753 - val_accuracy: 0.8875\n",
      "Epoch 35/49\n",
      "3285/3285 [==============================] - 3s 848us/step - loss: 0.2081 - accuracy: 0.9738 - val_loss: 0.2402 - val_accuracy: 0.9712\n",
      "Epoch 36/49\n",
      "3285/3285 [==============================] - 3s 839us/step - loss: 0.2451 - accuracy: 0.9656 - val_loss: 0.4011 - val_accuracy: 0.9366\n",
      "Epoch 37/49\n",
      "3285/3285 [==============================] - 3s 840us/step - loss: 0.2244 - accuracy: 0.9699 - val_loss: 0.3332 - val_accuracy: 0.9567\n",
      "Epoch 38/49\n",
      "3285/3285 [==============================] - 3s 905us/step - loss: 0.2290 - accuracy: 0.9717 - val_loss: 0.3263 - val_accuracy: 0.9488\n",
      "Epoch 39/49\n",
      "3285/3285 [==============================] - 3s 889us/step - loss: 0.2029 - accuracy: 0.9781 - val_loss: 0.2532 - val_accuracy: 0.9668\n",
      "Epoch 40/49\n",
      "3285/3285 [==============================] - 3s 851us/step - loss: 0.2285 - accuracy: 0.9723 - val_loss: 0.6764 - val_accuracy: 0.9041\n",
      "Epoch 41/49\n",
      "3285/3285 [==============================] - 3s 845us/step - loss: 0.2213 - accuracy: 0.9677 - val_loss: 0.4815 - val_accuracy: 0.8695\n",
      "Epoch 42/49\n",
      "3285/3285 [==============================] - 3s 939us/step - loss: 0.2149 - accuracy: 0.9699 - val_loss: 0.4441 - val_accuracy: 0.9250\n",
      "Epoch 43/49\n",
      "3285/3285 [==============================] - 3s 905us/step - loss: 0.1943 - accuracy: 0.9793 - val_loss: 0.2159 - val_accuracy: 0.9791\n",
      "Epoch 44/49\n",
      "3285/3285 [==============================] - 3s 933us/step - loss: 0.2093 - accuracy: 0.9699 - val_loss: 0.3177 - val_accuracy: 0.9394\n",
      "Epoch 45/49\n",
      "3285/3285 [==============================] - 3s 874us/step - loss: 0.2375 - accuracy: 0.9641 - val_loss: 0.1956 - val_accuracy: 0.9805\n",
      "Epoch 46/49\n",
      "3285/3285 [==============================] - 3s 868us/step - loss: 0.2063 - accuracy: 0.9760 - val_loss: 0.3386 - val_accuracy: 0.9474\n",
      "Epoch 47/49\n",
      "3285/3285 [==============================] - 3s 898us/step - loss: 0.2126 - accuracy: 0.9753 - val_loss: 0.2572 - val_accuracy: 0.9733\n",
      "Epoch 48/49\n",
      "3285/3285 [==============================] - 3s 903us/step - loss: 0.2132 - accuracy: 0.9732 - val_loss: 0.3720 - val_accuracy: 0.9430\n",
      "Epoch 49/49\n",
      "3285/3285 [==============================] - 3s 919us/step - loss: 0.1997 - accuracy: 0.9793 - val_loss: 0.2354 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18ff9e906c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train_Dynamic,\n",
    "          Y_train_Dynamic,\n",
    "          batch_size=8,\n",
    "          validation_data=(X_test_Dynamic, Y_test_Dynamic),\n",
    "          epochs=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                Walking  Walking Downstairs  Walking Upstairs\n",
      "True                                                             \n",
      "Walking                 492                   3                 1\n",
      "Walking Downstairs        2                 418                 0\n",
      "Walking Upstairs          0                  24               447\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix2(Y_test_Dynamic, model.predict(X_test_Dynamic), {0: 'Walking', 1: 'Walking Upstairs', 2: 'Walking Downstairs',}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387/1387 [==============================] - 0s 99us/step\n",
      "[0.23537334086938821, 0.9783706068992615]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_Dynamic, Y_test_Dynamic)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Dynamic_class_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"red\"> Observations </font></h1> \n",
    "\n",
    "- Dynamic class model has 97.83% validation accuracy.\n",
    "- Our Dynamic class model also performs very good but it is having some issues while identifying walking upstairs and walking downstairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Static class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 124, 32)           1472      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 122, 16)           1552      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 122, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 61, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 976)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                62528     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 65,747\n",
      "Trainable params: 65,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, 5, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.001), input_shape=(timesteps, input_dim)))\n",
    "model.add(Conv1D(16, 3, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.45))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4067 samples, validate on 1560 samples\n",
      "Epoch 1/30\n",
      "4067/4067 [==============================] - 1s 189us/step - loss: 0.5892 - accuracy: 0.8879 - val_loss: 0.5801 - val_accuracy: 0.8692\n",
      "Epoch 2/30\n",
      "4067/4067 [==============================] - 0s 84us/step - loss: 0.4342 - accuracy: 0.9095 - val_loss: 0.6168 - val_accuracy: 0.8449\n",
      "Epoch 3/30\n",
      "4067/4067 [==============================] - 0s 87us/step - loss: 0.3644 - accuracy: 0.9169 - val_loss: 0.5273 - val_accuracy: 0.8744\n",
      "Epoch 4/30\n",
      "4067/4067 [==============================] - 0s 93us/step - loss: 0.3208 - accuracy: 0.9159 - val_loss: 0.5319 - val_accuracy: 0.8859\n",
      "Epoch 5/30\n",
      "4067/4067 [==============================] - 0s 85us/step - loss: 0.2917 - accuracy: 0.9230 - val_loss: 0.5039 - val_accuracy: 0.8750\n",
      "Epoch 6/30\n",
      "4067/4067 [==============================] - 0s 83us/step - loss: 0.2709 - accuracy: 0.9216 - val_loss: 0.4587 - val_accuracy: 0.8615\n",
      "Epoch 7/30\n",
      "4067/4067 [==============================] - 0s 87us/step - loss: 0.2524 - accuracy: 0.9265 - val_loss: 0.5580 - val_accuracy: 0.8635\n",
      "Epoch 8/30\n",
      "4067/4067 [==============================] - 0s 86us/step - loss: 0.2461 - accuracy: 0.9248 - val_loss: 0.6068 - val_accuracy: 0.8692\n",
      "Epoch 9/30\n",
      "4067/4067 [==============================] - 0s 97us/step - loss: 0.2337 - accuracy: 0.9292 - val_loss: 0.5964 - val_accuracy: 0.8654\n",
      "Epoch 10/30\n",
      "4067/4067 [==============================] - 0s 86us/step - loss: 0.2276 - accuracy: 0.9292 - val_loss: 0.6412 - val_accuracy: 0.8436\n",
      "Epoch 11/30\n",
      "4067/4067 [==============================] - 0s 100us/step - loss: 0.2175 - accuracy: 0.9343 - val_loss: 0.5408 - val_accuracy: 0.8487\n",
      "Epoch 12/30\n",
      "4067/4067 [==============================] - 0s 94us/step - loss: 0.2122 - accuracy: 0.9348 - val_loss: 0.6241 - val_accuracy: 0.8583\n",
      "Epoch 13/30\n",
      "4067/4067 [==============================] - 0s 88us/step - loss: 0.2135 - accuracy: 0.9319 - val_loss: 0.6989 - val_accuracy: 0.8821\n",
      "Epoch 14/30\n",
      "4067/4067 [==============================] - 0s 95us/step - loss: 0.2003 - accuracy: 0.9371 - val_loss: 0.6297 - val_accuracy: 0.8801\n",
      "Epoch 15/30\n",
      "4067/4067 [==============================] - 0s 90us/step - loss: 0.2082 - accuracy: 0.9368 - val_loss: 0.5916 - val_accuracy: 0.8423\n",
      "Epoch 16/30\n",
      "4067/4067 [==============================] - 0s 98us/step - loss: 0.1944 - accuracy: 0.9412 - val_loss: 0.5883 - val_accuracy: 0.8571\n",
      "Epoch 17/30\n",
      "4067/4067 [==============================] - 0s 87us/step - loss: 0.1889 - accuracy: 0.9398 - val_loss: 0.8149 - val_accuracy: 0.8654\n",
      "Epoch 18/30\n",
      "4067/4067 [==============================] - 0s 93us/step - loss: 0.1917 - accuracy: 0.9390 - val_loss: 0.6948 - val_accuracy: 0.8641\n",
      "Epoch 19/30\n",
      "4067/4067 [==============================] - 0s 95us/step - loss: 0.1809 - accuracy: 0.9430 - val_loss: 0.6399 - val_accuracy: 0.8788\n",
      "Epoch 20/30\n",
      "4067/4067 [==============================] - 0s 88us/step - loss: 0.1828 - accuracy: 0.9439 - val_loss: 0.6057 - val_accuracy: 0.8590\n",
      "Epoch 21/30\n",
      "4067/4067 [==============================] - 0s 88us/step - loss: 0.1812 - accuracy: 0.9432 - val_loss: 0.6477 - val_accuracy: 0.8628\n",
      "Epoch 22/30\n",
      "4067/4067 [==============================] - 0s 90us/step - loss: 0.1860 - accuracy: 0.9380 - val_loss: 0.6618 - val_accuracy: 0.8833\n",
      "Epoch 23/30\n",
      "4067/4067 [==============================] - 0s 88us/step - loss: 0.1698 - accuracy: 0.9486 - val_loss: 0.6620 - val_accuracy: 0.8910\n",
      "Epoch 24/30\n",
      "4067/4067 [==============================] - 0s 99us/step - loss: 0.1818 - accuracy: 0.9415 - val_loss: 0.7011 - val_accuracy: 0.8769\n",
      "Epoch 25/30\n",
      "4067/4067 [==============================] - 0s 88us/step - loss: 0.1738 - accuracy: 0.9444 - val_loss: 0.7368 - val_accuracy: 0.8859\n",
      "Epoch 26/30\n",
      "4067/4067 [==============================] - 0s 89us/step - loss: 0.1627 - accuracy: 0.9469 - val_loss: 0.7011 - val_accuracy: 0.8558\n",
      "Epoch 27/30\n",
      "4067/4067 [==============================] - 0s 91us/step - loss: 0.1661 - accuracy: 0.9476 - val_loss: 0.7004 - val_accuracy: 0.8788\n",
      "Epoch 28/30\n",
      "4067/4067 [==============================] - 0s 98us/step - loss: 0.1630 - accuracy: 0.9511 - val_loss: 0.7455 - val_accuracy: 0.8808\n",
      "Epoch 29/30\n",
      "4067/4067 [==============================] - 0s 88us/step - loss: 0.1591 - accuracy: 0.9491 - val_loss: 0.6871 - val_accuracy: 0.8654\n",
      "Epoch 30/30\n",
      "4067/4067 [==============================] - 0s 89us/step - loss: 0.1616 - accuracy: 0.9503 - val_loss: 0.7667 - val_accuracy: 0.8891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18ffb985948>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train_Static,\n",
    "          Y_train_Static,\n",
    "          batch_size=64,\n",
    "          validation_data=(X_test_Static, Y_test_Static),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred      Laying  Sitting  Standing\n",
      "True                               \n",
      "Laying       400       91         0\n",
      "Sitting       55      477         0\n",
      "Standing       0       27       510\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix2(Y_test_Static, model.predict(X_test_Static), {0: 'Laying', 1: 'Sitting', 2: 'Standing',}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560/1560 [==============================] - 0s 91us/step\n",
      "[0.7667308768209739, 0.889102578163147]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_Static, Y_test_Static)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Static_class_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"red\"> Observations </font></h1> \n",
    "\n",
    "- Static class model has 88.91% validation accuracy.\n",
    "- Our Static class model performs good but it is having issues while identifying Laying and Sitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "class PredictActivity:\n",
    "    def __init__(self):\n",
    "        self.binary_model = None\n",
    "        self.dynamic_model = None\n",
    "        self.static_model = None\n",
    "\n",
    "    def loadModels(self, binModelPath, dynamicModelpath, staticModelPath):\n",
    "        self.binary_model = load_model(binModelPath)\n",
    "        self.dynamic_model = load_model(dynamicModelpath)\n",
    "        self.static_model = load_model(staticModelPath)\n",
    "  \n",
    "    def predict(self, X):\n",
    "        y_bin = np.argmax(self.binary_model.predict(X), axis=1)\n",
    "\n",
    "        X_dynamic = X[y_bin==1]\n",
    "        X_static = X[y_bin==0]\n",
    "\n",
    "        y_dynamic = np.argmax(self.dynamic_model.predict(X_dynamic), axis=1)\n",
    "        y_static = np.argmax(self.static_model.predict(X_static), axis=1)\n",
    "\n",
    "        y_dynamic = y_dynamic + 1\n",
    "        y_static = y_static + 4\n",
    "\n",
    "        output = np.zeros((X.shape[0]), dtype='int')\n",
    "        output[np.where(y_bin==1)[0]] = y_dynamic\n",
    "        output[np.where(y_bin==0)[0]] = y_static\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.65 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# Loading saved models\n",
    "predictactivity = PredictActivity()\n",
    "predictactivity.loadModels('class_model.h5', 'Dynamic_class_model.h5', 'Static_class_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9311163895486936"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking and printing the accuracy score on validation Data\n",
    "accuracy_score(Y_test, predictactivity.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[492   1   3   0   0   0]\n",
      " [  0 447  24   0   0   0]\n",
      " [  2   0 418   0   0   0]\n",
      " [  0   0   0 400  91   0]\n",
      " [  0   0   0  55 477   0]\n",
      " [  0   0   0   0  27 510]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(Y_test, predictactivity.predict(X_test), labels=range(1,7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"red\"> Observations </font></h1> \n",
    "\n",
    "- Final model has 93.11% validation accuracy.\n",
    "- Our Final model performs very good but it is having some issues while identifying some classes.\n",
    "- But the overall performance is preety good as compare to all the models I have previously tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---------------------+\n",
      "|             Model Name             | Validation accuracy |\n",
      "+------------------------------------+---------------------+\n",
      "|         2 class classifier         |         100%        |\n",
      "|        Dynamic class model         |        97.83%       |\n",
      "|         Static class model         |        88.91%       |\n",
      "| Divide & Conquer CNN - Final Model |        93.11%       |\n",
      "+------------------------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "t = PrettyTable()\n",
    "t.field_names= (\"Model Name\", \"Validation accuracy\")\n",
    "t.add_row([\"2 class classifier\", \"100%\"])\n",
    "t.add_row([\"Dynamic class model\", \"97.83%\"])\n",
    "t.add_row([\"Static class model\", \"88.91%\"])\n",
    "t.add_row([\"Divide & Conquer CNN - Final Model\", \"93.11%\"])\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"red\"> Procedure </font></h1> \n",
    "\n",
    "<b> Step - 1 : </b> I have tried several architectures with LSTM but it was giving validation accuracy around 91-92 %.\n",
    "\n",
    "<b> Step - 2 : </b> So as suggested I have tried Divide and Conquer CNN and I have achieved preety good results as compare to previous models. The steps are given below:\n",
    "\n",
    "- So divide and Conqure is a stratergy in which we divide our program into smaller parts and after performing operations on smaller parts we combine them.\n",
    "- Here for Human activity recognition too, we are first breaking our whole task into smaller tasks such as - Identifying Static class and Dyamic class. After identifying we are applying different models for both the classes.\n",
    "- For the 2 class classifier I have achieved the validation accuracy as 100%.\n",
    "- For the 2 Dynamic class model I have achieved the validation accuracy as 97.83%.\n",
    "- For the 2 Static class model I have achieved the validation accuracy as 88.91%.\n",
    "- After combing the final model gave the accuracy of 93.11%, which is very good because we have not taken any help from the experts and then also we are able to achieve this much accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
